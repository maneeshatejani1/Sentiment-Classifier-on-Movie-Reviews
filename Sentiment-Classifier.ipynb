{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sigmoid Function\n",
    "def sigmoid (Z):\n",
    "    return 1/(1+np.exp(-Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probability\n",
    "def probability(X,Theta):\n",
    "    Z= X @ Theta #same as Z = X.dot(Theta) or np.dot(X,Theta)\n",
    "    return sigmoid (Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "def predict(X,Theta):\n",
    "    p = np.round(probability(X,Theta))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-entropy loss function for BGD\n",
    "def computeCostBatch(X,Y,Theta):\n",
    "    m=Y.size\n",
    "    Hx = probability (X,Theta)\n",
    "    return (-1/m)*(Y.T @ np.log(Hx) + (1-Y).T @ np.log(1-Hx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-entropy loss function for SGD\n",
    "def computeCostStochastic(X,Y,Theta):\n",
    "    m=Y.size\n",
    "    Hx = probability (X,Theta)\n",
    "    return (-1)*(Y.T @ np.log(Hx) + (1-Y).T @ np.log(1-Hx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch Gradient Descent\n",
    "def BGD (X,Y,alpha,n_epoch):\n",
    "    print(\"\\nRunning BGD.....\\n\")\n",
    "    m=Y.size\n",
    "    features=X[0].size\n",
    "    J=list()\n",
    "    Theta=np.zeros((features,1))\n",
    "    for i in range(n_epoch):\n",
    "        error=(probability(X,Theta))-Y\n",
    "        errorIntoX = X.T @ error\n",
    "        Theta=Theta-(alpha * (1/m) * errorIntoX)\n",
    "        J.append(computeCostBatch(X,Y,Theta))\n",
    "    return Theta, J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic Gradient Descent\n",
    "def SGD (X, Y, alpha, n_epoch):\n",
    "    print(\"\\nRunning SGD.....\\n\")\n",
    "    m=Y.size\n",
    "    features=X[0].size\n",
    "    J=list()\n",
    "    Theta=np.zeros((features,1))\n",
    "    for i in range (n_epoch):\n",
    "        cost = 0.0\n",
    "        r_indices = random.sample(range(m),m)\n",
    "        for i in r_indices:\n",
    "            oneX = X[i,:].reshape(1,features)\n",
    "            oneY = Y[i].reshape(1,1)\n",
    "            error = (probability(oneX,Theta))-oneY\n",
    "            errorIntoX = oneX.T @ error\n",
    "            Theta=Theta-(alpha * errorIntoX)\n",
    "            cost = cost + computeCostStochastic(oneX,oneY,Theta)\n",
    "        J.append(cost/m)\n",
    "    return Theta, J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Report evaluation\n",
    "def eval_GD (Theta,Test_X,Test_Y):\n",
    "    Predictions = predict (Test_X, Theta)\n",
    "    m = Test_Y.size\n",
    "    Tn, Tp, Fn, Fp = 0, 0, 0, 0\n",
    "    for i in range (m):\n",
    "        if (Predictions[i]==Test_Y[i]):\n",
    "            if (Predictions[i]==1):\n",
    "                Tp=Tp+1\n",
    "            else:\n",
    "                Tn=Tn+1\n",
    "        else:\n",
    "            if (Predictions[i]==1):\n",
    "                Fp=Fp+1\n",
    "            else:\n",
    "                Fn=Fn+1\n",
    "    print (\"No. of total Tp (classifier:pos, label:pos)= \",Tp)\n",
    "    print (\"No. of total Fp (classifier:pos, label:neg)= \",Fp)\n",
    "    print (\"No. of total Fn (classifier:neg, label:pos)= \",Fn)\n",
    "    print (\"No. of total Tn (classifier:neg, label:neg)= \",Tn)\n",
    "    Accuracy = (Tn+Tp)/(Tn+Fp+Fn+Tp)\n",
    "    Recall = Tp/(Fn+Tp)\n",
    "    Precision = Tp/(Fp+Tp)\n",
    "    f1 = (2*Precision*Recall)/(Precision+Recall)\n",
    "    print(\"Accuray: \", Accuracy)\n",
    "    print(\"Recall: \", Recall)\n",
    "    print(\"Precision: \", Precision)\n",
    "    print(\"F1 Score: \", f1)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes directory and gives Train_X, Train_Y, Test_X, Test_Y\n",
    "def extract_data (dir):\n",
    "    Train_X = []\n",
    "    Train_Y = []\n",
    "    Test_X = []\n",
    "    Test_Y = []\n",
    "    for train_test in os.listdir(dir+\"//\"):\n",
    "        if (train_test.endswith('.txt')):\n",
    "            continue;\n",
    "        print(\"Loading:\",train_test,\"data...\")\n",
    "        p_counts = [] #List of count(positive words) ∈ reviews\n",
    "        n_counts = [] #List of count(negative words) ∈ reviews\n",
    "        ratings = [] #List of Star Ratings (1-10 scale)\n",
    "        log_counts = [] #List of log(word count of reviews)\n",
    "        no_flags = [] #List of no_flags (1 if “no” ∈ review, 0 otherwise)\n",
    "        ex_flags = [] #List of ex_flags (1 if “!” ∈ review, 0 otherwise)\n",
    "        ys = [] #List of y labels (1 if positive, 0 otherwise)\n",
    "        count=1\n",
    "        for pos_neg in os.listdir(dir+\"//\"+train_test+\"//\"):\n",
    "            for i in os.listdir(dir+\"//\"+train_test+\"//\"+pos_neg+\"//\"):\n",
    "                #getting text\n",
    "                f = open (dir+\"//\"+train_test+\"//\"+pos_neg+\"//\"+i,\"r\",encoding=\"utf8\")\n",
    "                text = f.read()\n",
    "                textl=text.lower()\n",
    "                f.close()\n",
    "                #getting p_count\n",
    "                p_count=0 #count(positive words) ∈ review\n",
    "                f = open (dir+\"//\"+\"positive-words.txt\")\n",
    "                for line in f:\n",
    "                    if (line in textl):\n",
    "                        p_count = p_count +1\n",
    "                f.close()\n",
    "                p_counts.append(p_count)\n",
    "                #getting n_count\n",
    "                n_count=0 #count(negative words) ∈ review\n",
    "                f = open (dir+\"//\"+\"negative-words.txt\")\n",
    "                for line in f:\n",
    "                    if (line in textl):\n",
    "                        n_count = n_count +1\n",
    "                f.close()\n",
    "                n_counts.append(n_count)\n",
    "                #rating\n",
    "                rating= \"\" #Star Rating (1-10 scale)\n",
    "                dashIndex=i.index('_')\n",
    "                k = dashIndex+1\n",
    "                while (i[k]!='.'):\n",
    "                    rating= rating + i[k]\n",
    "                    k=k+1\n",
    "                ratings.append(int(rating))\n",
    "                #log_count\n",
    "                log_count = math.log(text.count(' ')+1) #log(word count of review)\n",
    "                log_counts.append(log_count)\n",
    "                #no_flag\n",
    "                no_flag=0 #(1 if “no” ∈ review, 0 otherwise)\n",
    "                possible_nos = [\"no \",\"no,\",\"no.\"]\n",
    "                for e in possible_nos:\n",
    "                    if (e in textl):\n",
    "                        no_flag=1\n",
    "                        break;\n",
    "                no_flags.append(no_flag)\n",
    "                #ex_flag\n",
    "                ex_flag=0 #(1 if “!” ∈ review, 0 otherwise)\n",
    "                if ('!' in text):\n",
    "                    ex_flag=1\n",
    "                ex_flags.append(ex_flag)\n",
    "                #y label\n",
    "                y=0 #1 if positive, 0 otherwise\n",
    "                if (pos_neg==\"pos\"):\n",
    "                    y=1\n",
    "                ys.append(y)\n",
    "                \n",
    "                count=count+1\n",
    "                if(count%1000==0):\n",
    "                    print(count,\"Loaded!\",end=' ')\n",
    "        if (train_test==\"train\"):\n",
    "            Train_X.append(p_counts)\n",
    "            Train_X.append(n_counts)\n",
    "            Train_X.append(ratings)\n",
    "            Train_X.append(log_counts)\n",
    "            Train_X.append(no_flags)\n",
    "            Train_X.append(ex_flags)\n",
    "            Train_Y.append(ys)\n",
    "        else:\n",
    "            Test_X.append(p_counts)\n",
    "            Test_X.append(n_counts)\n",
    "            Test_X.append(ratings)\n",
    "            Test_X.append(log_counts)\n",
    "            Test_X.append(no_flags)\n",
    "            Test_X.append(ex_flags)\n",
    "            Test_Y.append(ys)\n",
    "        print(\"\\n\")\n",
    "    return Train_X, Train_Y, Test_X, Test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: test data...\n",
      "1000 Loaded! 2000 Loaded! 3000 Loaded! 4000 Loaded! 5000 Loaded! 6000 Loaded! 7000 Loaded! 8000 Loaded! 9000 Loaded! 10000 Loaded! 11000 Loaded! 12000 Loaded! 13000 Loaded! 14000 Loaded! 15000 Loaded! 16000 Loaded! 17000 Loaded! 18000 Loaded! 19000 Loaded! 20000 Loaded! 21000 Loaded! 22000 Loaded! 23000 Loaded! 24000 Loaded! 25000 Loaded! \n",
      "\n",
      "Loading: train data...\n",
      "1000 Loaded! 2000 Loaded! 3000 Loaded! 4000 Loaded! 5000 Loaded! 6000 Loaded! 7000 Loaded! 8000 Loaded! 9000 Loaded! 10000 Loaded! 11000 Loaded! 12000 Loaded! 13000 Loaded! 14000 Loaded! 15000 Loaded! 16000 Loaded! 17000 Loaded! 18000 Loaded! 19000 Loaded! 20000 Loaded! 21000 Loaded! 22000 Loaded! 23000 Loaded! 24000 Loaded! 25000 Loaded! \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "#Main Function part 1\n",
    "\n",
    "#PREPROCESSING\n",
    "\n",
    "#Takes few minutes to load\n",
    "#calling a function which takes the directory and gives Train_X, Train_Y, Test_X, Test_Y\n",
    "Train_X, Train_Y, Test_X, Test_Y = extract_data(\"Dataset\")\n",
    "\n",
    "#convert list to numpy array and reshaping\n",
    "Tr_X, Tr_Y, Te_X, Te_Y = np.array(Train_X).T, np.array(Train_Y).T, np.array(Test_X).T, np.array(Test_Y).T\n",
    "\n",
    "#feature scaling\n",
    "Tr_X = (Tr_X - np.mean(Tr_X))/np.std(Tr_X)\n",
    "Te_X = (Te_X - np.mean(Te_X))/np.std(Te_X)\n",
    "\n",
    "#No. of instances in training data and test data\n",
    "Tr_m = Tr_Y.size\n",
    "Te_m = Te_Y.size\n",
    "\n",
    "#adding columnn of ones\n",
    "Tr_X=np.c_[np.ones((Tr_m)),Tr_X]\n",
    "Te_X=np.c_[np.ones((Te_m)),Te_X]\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running BGD.....\n",
      "\n",
      "\n",
      "Values of Theta: [[-0.52622483  0.35138005  0.340718    1.79367318 -0.59562546  0.23398085\n",
      "   0.27737841]]\n",
      "\n",
      "Few values of J (BGD): [array([[0.68989269]]), array([[0.49579861]]), array([[0.39468187]]), array([[0.32794904]]), array([[0.28101256]]), array([[0.24648094]]), array([[0.22011331]]), array([[0.19935077]]), array([[0.18258101]]), array([[0.16874713]])]\n",
      "\n",
      "*****EVALUATING BGD*****\n",
      "No. of total Tp (classifier:pos, label:pos)=  12500\n",
      "No. of total Fp (classifier:pos, label:neg)=  0\n",
      "No. of total Fn (classifier:neg, label:pos)=  0\n",
      "No. of total Tn (classifier:neg, label:neg)=  12500\n",
      "Accuray:  1.0\n",
      "Recall:  1.0\n",
      "Precision:  1.0\n",
      "F1 Score:  1.0\n",
      "\n",
      "Running SGD.....\n",
      "\n",
      "\n",
      "Values of Theta: [[-2.31113167  1.54309974  1.49282695  6.51441069 -2.11580145  1.01494313\n",
      "   1.13107429]]\n",
      "\n",
      "Few values of J (SGD): [array([[0.04482141]]), array([[0.01115177]])]\n",
      "\n",
      "*****EVALUATING SGD*****\n",
      "No. of total Tp (classifier:pos, label:pos)=  12500\n",
      "No. of total Fp (classifier:pos, label:neg)=  0\n",
      "No. of total Fn (classifier:neg, label:pos)=  0\n",
      "No. of total Tn (classifier:neg, label:neg)=  12500\n",
      "Accuray:  1.0\n",
      "Recall:  1.0\n",
      "Precision:  1.0\n",
      "F1 Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "#Main Function part 2\n",
    "\n",
    "#IMPLEMENTATION AND EVALUATION\n",
    "\n",
    "#running Batch Gradient Descent\n",
    "alpha , n_epoch = 0.01 , 1000\n",
    "ThetaB,J = BGD (Tr_X,Tr_Y,alpha,n_epoch)\n",
    "print(\"\\nValues of Theta:\", ThetaB.T)\n",
    "print(\"\\nFew values of J (BGD):\",J[0:-1:100])\n",
    "\n",
    "#evaluating BGD\n",
    "print(\"\\n*****EVALUATING BGD*****\")\n",
    "eval_GD (ThetaB,Te_X,Te_Y)\n",
    "\n",
    "#running Stochastic Gradient Descent\n",
    "alpha , n_epoch = 0.01 , 2\n",
    "ThetaS,J = SGD (Tr_X,Tr_Y,alpha,n_epoch)\n",
    "print(\"\\nValues of Theta:\", ThetaS.T)\n",
    "print(\"\\nFew values of J (SGD):\",J)\n",
    "\n",
    "#evaluating SGD\n",
    "print(\"\\n*****EVALUATING SGD*****\")\n",
    "eval_GD (ThetaS,Te_X,Te_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
